// automatically generated by the FlatBuffers compiler, do not modify


// @generated

use core::mem;
use core::cmp::Ordering;

extern crate flatbuffers;
use self::flatbuffers::{EndianScalar, Follow};

#[allow(unused_imports, dead_code)]
pub mod open_mahjong {

  use core::mem;
  use core::cmp::Ordering;

  extern crate flatbuffers;
  use self::flatbuffers::{EndianScalar, Follow};

#[deprecated(since = "2.0.0", note = "Use associated constants instead. This will no longer be generated in 2021.")]
pub const ENUM_MIN_ACTION_TYPE: u32 = 0;
#[deprecated(since = "2.0.0", note = "Use associated constants instead. This will no longer be generated in 2021.")]
pub const ENUM_MAX_ACTION_TYPE: u32 = 6;
#[deprecated(since = "2.0.0", note = "Use associated constants instead. This will no longer be generated in 2021.")]
#[allow(non_camel_case_types)]
pub const ENUM_VALUES_ACTION_TYPE: [ActionType; 7] = [
  ActionType::ACTION_SYNC,
  ActionType::ACTION_SUTEHAI,
  ActionType::ACTION_CHII,
  ActionType::ACTION_PON,
  ActionType::ACTION_KAN,
  ActionType::ACTION_TSUMO,
  ActionType::ACTION_NAGASHI,
];

#[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash, Default)]
#[repr(transparent)]
pub struct ActionType(pub u32);
#[allow(non_upper_case_globals)]
impl ActionType {
  pub const ACTION_SYNC: Self = Self(0);
  pub const ACTION_SUTEHAI: Self = Self(1);
  pub const ACTION_CHII: Self = Self(2);
  pub const ACTION_PON: Self = Self(3);
  pub const ACTION_KAN: Self = Self(4);
  pub const ACTION_TSUMO: Self = Self(5);
  pub const ACTION_NAGASHI: Self = Self(6);

  pub const ENUM_MIN: u32 = 0;
  pub const ENUM_MAX: u32 = 6;
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::ACTION_SYNC,
    Self::ACTION_SUTEHAI,
    Self::ACTION_CHII,
    Self::ACTION_PON,
    Self::ACTION_KAN,
    Self::ACTION_TSUMO,
    Self::ACTION_NAGASHI,
  ];
  /// Returns the variant's name or "" if unknown.
  pub fn variant_name(self) -> Option<&'static str> {
    match self {
      Self::ACTION_SYNC => Some("ACTION_SYNC"),
      Self::ACTION_SUTEHAI => Some("ACTION_SUTEHAI"),
      Self::ACTION_CHII => Some("ACTION_CHII"),
      Self::ACTION_PON => Some("ACTION_PON"),
      Self::ACTION_KAN => Some("ACTION_KAN"),
      Self::ACTION_TSUMO => Some("ACTION_TSUMO"),
      Self::ACTION_NAGASHI => Some("ACTION_NAGASHI"),
      _ => None,
    }
  }
}
impl core::fmt::Debug for ActionType {
  fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {
    if let Some(name) = self.variant_name() {
      f.write_str(name)
    } else {
      f.write_fmt(format_args!("<UNKNOWN {:?}>", self.0))
    }
  }
}
impl<'a> flatbuffers::Follow<'a> for ActionType {
  type Inner = Self;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    let b = flatbuffers::read_scalar_at::<u32>(buf, loc);
    Self(b)
  }
}

impl flatbuffers::Push for ActionType {
    type Output = ActionType;
    #[inline]
    unsafe fn push(&self, dst: &mut [u8], _written_len: usize) {
        flatbuffers::emplace_scalar::<u32>(dst, self.0);
    }
}

impl flatbuffers::EndianScalar for ActionType {
  type Scalar = u32;
  #[inline]
  fn to_little_endian(self) -> u32 {
    self.0.to_le()
  }
  #[inline]
  #[allow(clippy::wrong_self_convention)]
  fn from_little_endian(v: u32) -> Self {
    let b = u32::from_le(v);
    Self(b)
  }
}

impl<'a> flatbuffers::Verifiable for ActionType {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    u32::run_verifier(v, pos)
  }
}

impl flatbuffers::SimpleToVerifyInSlice for ActionType {}
#[deprecated(since = "2.0.0", note = "Use associated constants instead. This will no longer be generated in 2021.")]
pub const ENUM_MIN_MENTSU_TYPE: u8 = 0;
#[deprecated(since = "2.0.0", note = "Use associated constants instead. This will no longer be generated in 2021.")]
pub const ENUM_MAX_MENTSU_TYPE: u8 = 4;
#[deprecated(since = "2.0.0", note = "Use associated constants instead. This will no longer be generated in 2021.")]
#[allow(non_camel_case_types)]
pub const ENUM_VALUES_MENTSU_TYPE: [MentsuType; 5] = [
  MentsuType::TYPE_SHUNTSU,
  MentsuType::TYPE_KOUTSU,
  MentsuType::TYPE_MINKAN,
  MentsuType::TYPE_ANKAN,
  MentsuType::TYPE_ATAMA,
];

#[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash, Default)]
#[repr(transparent)]
pub struct MentsuType(pub u8);
#[allow(non_upper_case_globals)]
impl MentsuType {
  pub const TYPE_SHUNTSU: Self = Self(0);
  pub const TYPE_KOUTSU: Self = Self(1);
  pub const TYPE_MINKAN: Self = Self(2);
  pub const TYPE_ANKAN: Self = Self(3);
  pub const TYPE_ATAMA: Self = Self(4);

  pub const ENUM_MIN: u8 = 0;
  pub const ENUM_MAX: u8 = 4;
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::TYPE_SHUNTSU,
    Self::TYPE_KOUTSU,
    Self::TYPE_MINKAN,
    Self::TYPE_ANKAN,
    Self::TYPE_ATAMA,
  ];
  /// Returns the variant's name or "" if unknown.
  pub fn variant_name(self) -> Option<&'static str> {
    match self {
      Self::TYPE_SHUNTSU => Some("TYPE_SHUNTSU"),
      Self::TYPE_KOUTSU => Some("TYPE_KOUTSU"),
      Self::TYPE_MINKAN => Some("TYPE_MINKAN"),
      Self::TYPE_ANKAN => Some("TYPE_ANKAN"),
      Self::TYPE_ATAMA => Some("TYPE_ATAMA"),
      _ => None,
    }
  }
}
impl core::fmt::Debug for MentsuType {
  fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {
    if let Some(name) = self.variant_name() {
      f.write_str(name)
    } else {
      f.write_fmt(format_args!("<UNKNOWN {:?}>", self.0))
    }
  }
}
impl<'a> flatbuffers::Follow<'a> for MentsuType {
  type Inner = Self;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    let b = flatbuffers::read_scalar_at::<u8>(buf, loc);
    Self(b)
  }
}

impl flatbuffers::Push for MentsuType {
    type Output = MentsuType;
    #[inline]
    unsafe fn push(&self, dst: &mut [u8], _written_len: usize) {
        flatbuffers::emplace_scalar::<u8>(dst, self.0);
    }
}

impl flatbuffers::EndianScalar for MentsuType {
  type Scalar = u8;
  #[inline]
  fn to_little_endian(self) -> u8 {
    self.0.to_le()
  }
  #[inline]
  #[allow(clippy::wrong_self_convention)]
  fn from_little_endian(v: u8) -> Self {
    let b = u8::from_le(v);
    Self(b)
  }
}

impl<'a> flatbuffers::Verifiable for MentsuType {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    u8::run_verifier(v, pos)
  }
}

impl flatbuffers::SimpleToVerifyInSlice for MentsuType {}
#[deprecated(since = "2.0.0", note = "Use associated constants instead. This will no longer be generated in 2021.")]
pub const ENUM_MIN_MENTSU_FLAG: u8 = 0;
#[deprecated(since = "2.0.0", note = "Use associated constants instead. This will no longer be generated in 2021.")]
pub const ENUM_MAX_MENTSU_FLAG: u8 = 4;
#[deprecated(since = "2.0.0", note = "Use associated constants instead. This will no longer be generated in 2021.")]
#[allow(non_camel_case_types)]
pub const ENUM_VALUES_MENTSU_FLAG: [MentsuFlag; 5] = [
  MentsuFlag::FLAG_NONE,
  MentsuFlag::FLAG_KAMICHA,
  MentsuFlag::FLAG_TOIMEN,
  MentsuFlag::FLAG_SIMOCHA,
  MentsuFlag::FLAG_AGARI,
];

#[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash, Default)]
#[repr(transparent)]
pub struct MentsuFlag(pub u8);
#[allow(non_upper_case_globals)]
impl MentsuFlag {
  pub const FLAG_NONE: Self = Self(0);
  pub const FLAG_KAMICHA: Self = Self(1);
  pub const FLAG_TOIMEN: Self = Self(2);
  pub const FLAG_SIMOCHA: Self = Self(3);
  pub const FLAG_AGARI: Self = Self(4);

  pub const ENUM_MIN: u8 = 0;
  pub const ENUM_MAX: u8 = 4;
  pub const ENUM_VALUES: &'static [Self] = &[
    Self::FLAG_NONE,
    Self::FLAG_KAMICHA,
    Self::FLAG_TOIMEN,
    Self::FLAG_SIMOCHA,
    Self::FLAG_AGARI,
  ];
  /// Returns the variant's name or "" if unknown.
  pub fn variant_name(self) -> Option<&'static str> {
    match self {
      Self::FLAG_NONE => Some("FLAG_NONE"),
      Self::FLAG_KAMICHA => Some("FLAG_KAMICHA"),
      Self::FLAG_TOIMEN => Some("FLAG_TOIMEN"),
      Self::FLAG_SIMOCHA => Some("FLAG_SIMOCHA"),
      Self::FLAG_AGARI => Some("FLAG_AGARI"),
      _ => None,
    }
  }
}
impl core::fmt::Debug for MentsuFlag {
  fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {
    if let Some(name) = self.variant_name() {
      f.write_str(name)
    } else {
      f.write_fmt(format_args!("<UNKNOWN {:?}>", self.0))
    }
  }
}
impl<'a> flatbuffers::Follow<'a> for MentsuFlag {
  type Inner = Self;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    let b = flatbuffers::read_scalar_at::<u8>(buf, loc);
    Self(b)
  }
}

impl flatbuffers::Push for MentsuFlag {
    type Output = MentsuFlag;
    #[inline]
    unsafe fn push(&self, dst: &mut [u8], _written_len: usize) {
        flatbuffers::emplace_scalar::<u8>(dst, self.0);
    }
}

impl flatbuffers::EndianScalar for MentsuFlag {
  type Scalar = u8;
  #[inline]
  fn to_little_endian(self) -> u8 {
    self.0.to_le()
  }
  #[inline]
  #[allow(clippy::wrong_self_convention)]
  fn from_little_endian(v: u8) -> Self {
    let b = u8::from_le(v);
    Self(b)
  }
}

impl<'a> flatbuffers::Verifiable for MentsuFlag {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    u8::run_verifier(v, pos)
  }
}

impl flatbuffers::SimpleToVerifyInSlice for MentsuFlag {}
// struct FixedString, aligned to 1
#[repr(transparent)]
#[derive(Clone, Copy, PartialEq)]
pub struct FixedString(pub [u8; 256]);
impl Default for FixedString { 
  fn default() -> Self { 
    Self([0; 256])
  }
}
impl core::fmt::Debug for FixedString {
  fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {
    f.debug_struct("FixedString")
      .field("n1", &self.n1())
      .field("n2", &self.n2())
      .field("n3", &self.n3())
      .field("n4", &self.n4())
      .field("n5", &self.n5())
      .field("n6", &self.n6())
      .field("n7", &self.n7())
      .field("n8", &self.n8())
      .finish()
  }
}

impl flatbuffers::SimpleToVerifyInSlice for FixedString {}
impl<'a> flatbuffers::Follow<'a> for FixedString {
  type Inner = &'a FixedString;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    <&'a FixedString>::follow(buf, loc)
  }
}
impl<'a> flatbuffers::Follow<'a> for &'a FixedString {
  type Inner = &'a FixedString;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    flatbuffers::follow_cast_ref::<FixedString>(buf, loc)
  }
}
impl<'b> flatbuffers::Push for FixedString {
    type Output = FixedString;
    #[inline]
    unsafe fn push(&self, dst: &mut [u8], _written_len: usize) {
        let src = ::core::slice::from_raw_parts(self as *const FixedString as *const u8, Self::size());
        dst.copy_from_slice(src);
    }
}

impl<'a> flatbuffers::Verifiable for FixedString {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    v.in_buffer::<Self>(pos)
  }
}

impl<'a> FixedString {
  #[allow(clippy::too_many_arguments)]
  pub fn new(
    n1: &[u8; 32],
    n2: &[u8; 32],
    n3: &[u8; 32],
    n4: &[u8; 32],
    n5: &[u8; 32],
    n6: &[u8; 32],
    n7: &[u8; 32],
    n8: &[u8; 32],
  ) -> Self {
    let mut s = Self([0; 256]);
    s.set_n1(n1);
    s.set_n2(n2);
    s.set_n3(n3);
    s.set_n4(n4);
    s.set_n5(n5);
    s.set_n6(n6);
    s.set_n7(n7);
    s.set_n8(n8);
    s
  }

  pub fn n1(&'a self) -> flatbuffers::Array<'a, u8, 32> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 0) }
  }

  pub fn set_n1(&mut self, items: &[u8; 32]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::emplace_scalar_array(&mut self.0, 0, items) };
  }

  pub fn n2(&'a self) -> flatbuffers::Array<'a, u8, 32> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 32) }
  }

  pub fn set_n2(&mut self, items: &[u8; 32]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::emplace_scalar_array(&mut self.0, 32, items) };
  }

  pub fn n3(&'a self) -> flatbuffers::Array<'a, u8, 32> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 64) }
  }

  pub fn set_n3(&mut self, items: &[u8; 32]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::emplace_scalar_array(&mut self.0, 64, items) };
  }

  pub fn n4(&'a self) -> flatbuffers::Array<'a, u8, 32> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 96) }
  }

  pub fn set_n4(&mut self, items: &[u8; 32]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::emplace_scalar_array(&mut self.0, 96, items) };
  }

  pub fn n5(&'a self) -> flatbuffers::Array<'a, u8, 32> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 128) }
  }

  pub fn set_n5(&mut self, items: &[u8; 32]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::emplace_scalar_array(&mut self.0, 128, items) };
  }

  pub fn n6(&'a self) -> flatbuffers::Array<'a, u8, 32> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 160) }
  }

  pub fn set_n6(&mut self, items: &[u8; 32]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::emplace_scalar_array(&mut self.0, 160, items) };
  }

  pub fn n7(&'a self) -> flatbuffers::Array<'a, u8, 32> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 192) }
  }

  pub fn set_n7(&mut self, items: &[u8; 32]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::emplace_scalar_array(&mut self.0, 192, items) };
  }

  pub fn n8(&'a self) -> flatbuffers::Array<'a, u8, 32> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 224) }
  }

  pub fn set_n8(&mut self, items: &[u8; 32]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::emplace_scalar_array(&mut self.0, 224, items) };
  }

  pub fn unpack(&self) -> FixedStringT {
    FixedStringT {
      n1: self.n1().into(),
      n2: self.n2().into(),
      n3: self.n3().into(),
      n4: self.n4().into(),
      n5: self.n5().into(),
      n6: self.n6().into(),
      n7: self.n7().into(),
      n8: self.n8().into(),
    }
  }
}

#[derive(Debug, Clone, PartialEq, Default)]
pub struct FixedStringT {
  pub n1: [u8; 32],
  pub n2: [u8; 32],
  pub n3: [u8; 32],
  pub n4: [u8; 32],
  pub n5: [u8; 32],
  pub n6: [u8; 32],
  pub n7: [u8; 32],
  pub n8: [u8; 32],
}
impl FixedStringT {
  pub fn pack(&self) -> FixedString {
    FixedString::new(
      &self.n1,
      &self.n2,
      &self.n3,
      &self.n4,
      &self.n5,
      &self.n6,
      &self.n7,
      &self.n8,
    )
  }
}

// struct Pai, aligned to 1
#[repr(transparent)]
#[derive(Clone, Copy, PartialEq)]
pub struct Pai(pub [u8; 5]);
impl Default for Pai { 
  fn default() -> Self { 
    Self([0; 5])
  }
}
impl core::fmt::Debug for Pai {
  fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {
    f.debug_struct("Pai")
      .field("pai_num", &self.pai_num())
      .field("id", &self.id())
      .field("is_tsumogiri", &self.is_tsumogiri())
      .field("is_riichi", &self.is_riichi())
      .field("is_nakare", &self.is_nakare())
      .finish()
  }
}

impl flatbuffers::SimpleToVerifyInSlice for Pai {}
impl<'a> flatbuffers::Follow<'a> for Pai {
  type Inner = &'a Pai;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    <&'a Pai>::follow(buf, loc)
  }
}
impl<'a> flatbuffers::Follow<'a> for &'a Pai {
  type Inner = &'a Pai;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    flatbuffers::follow_cast_ref::<Pai>(buf, loc)
  }
}
impl<'b> flatbuffers::Push for Pai {
    type Output = Pai;
    #[inline]
    unsafe fn push(&self, dst: &mut [u8], _written_len: usize) {
        let src = ::core::slice::from_raw_parts(self as *const Pai as *const u8, Self::size());
        dst.copy_from_slice(src);
    }
}

impl<'a> flatbuffers::Verifiable for Pai {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    v.in_buffer::<Self>(pos)
  }
}

impl<'a> Pai {
  #[allow(clippy::too_many_arguments)]
  pub fn new(
    pai_num: u8,
    id: u8,
    is_tsumogiri: bool,
    is_riichi: bool,
    is_nakare: bool,
  ) -> Self {
    let mut s = Self([0; 5]);
    s.set_pai_num(pai_num);
    s.set_id(id);
    s.set_is_tsumogiri(is_tsumogiri);
    s.set_is_riichi(is_riichi);
    s.set_is_nakare(is_nakare);
    s
  }

  pub fn pai_num(&self) -> u8 {
    let mut mem = core::mem::MaybeUninit::<<u8 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[0..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u8 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_pai_num(&mut self, x: u8) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[0..].as_mut_ptr(),
        core::mem::size_of::<<u8 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn id(&self) -> u8 {
    let mut mem = core::mem::MaybeUninit::<<u8 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[1..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u8 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_id(&mut self, x: u8) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[1..].as_mut_ptr(),
        core::mem::size_of::<<u8 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn is_tsumogiri(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[2..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_is_tsumogiri(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[2..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn is_riichi(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[3..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_is_riichi(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[3..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn is_nakare(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[4..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_is_nakare(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[4..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn unpack(&self) -> PaiT {
    PaiT {
      pai_num: self.pai_num(),
      id: self.id(),
      is_tsumogiri: self.is_tsumogiri(),
      is_riichi: self.is_riichi(),
      is_nakare: self.is_nakare(),
    }
  }
}

#[derive(Debug, Clone, PartialEq, Default)]
pub struct PaiT {
  pub pai_num: u8,
  pub id: u8,
  pub is_tsumogiri: bool,
  pub is_riichi: bool,
  pub is_nakare: bool,
}
impl PaiT {
  pub fn pack(&self) -> Pai {
    Pai::new(
      self.pai_num,
      self.id,
      self.is_tsumogiri,
      self.is_riichi,
      self.is_nakare,
    )
  }
}

// struct Taku, aligned to 4
#[repr(transparent)]
#[derive(Clone, Copy, PartialEq)]
pub struct Taku(pub [u8; 684]);
impl Default for Taku { 
  fn default() -> Self { 
    Self([0; 684])
  }
}
impl core::fmt::Debug for Taku {
  fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {
    f.debug_struct("Taku")
      .field("n1", &self.n1())
      .field("n2", &self.n2())
      .field("n3", &self.n3())
      .field("n4", &self.n4())
      .field("n5", &self.n5())
      .field("length", &self.length())
      .finish()
  }
}

impl flatbuffers::SimpleToVerifyInSlice for Taku {}
impl<'a> flatbuffers::Follow<'a> for Taku {
  type Inner = &'a Taku;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    <&'a Taku>::follow(buf, loc)
  }
}
impl<'a> flatbuffers::Follow<'a> for &'a Taku {
  type Inner = &'a Taku;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    flatbuffers::follow_cast_ref::<Taku>(buf, loc)
  }
}
impl<'b> flatbuffers::Push for Taku {
    type Output = Taku;
    #[inline]
    unsafe fn push(&self, dst: &mut [u8], _written_len: usize) {
        let src = ::core::slice::from_raw_parts(self as *const Taku as *const u8, Self::size());
        dst.copy_from_slice(src);
    }
}

impl<'a> flatbuffers::Verifiable for Taku {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    v.in_buffer::<Self>(pos)
  }
}

impl<'a> Taku {
  #[allow(clippy::too_many_arguments)]
  pub fn new(
    n1: &[Pai; 32],
    n2: &[Pai; 32],
    n3: &[Pai; 32],
    n4: &[Pai; 32],
    n5: &[Pai; 8],
    length: u32,
  ) -> Self {
    let mut s = Self([0; 684]);
    s.set_n1(n1);
    s.set_n2(n2);
    s.set_n3(n3);
    s.set_n4(n4);
    s.set_n5(n5);
    s.set_length(length);
    s
  }

  pub fn n1(&'a self) -> flatbuffers::Array<'a, Pai, 32> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 0) }
  }

  pub fn set_n1(&mut self, x: &[Pai; 32]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe {
      core::ptr::copy(
        x.as_ptr() as *const u8,
        self.0.as_mut_ptr().add(0),
        160,
      );
    }
  }

  pub fn n2(&'a self) -> flatbuffers::Array<'a, Pai, 32> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 160) }
  }

  pub fn set_n2(&mut self, x: &[Pai; 32]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe {
      core::ptr::copy(
        x.as_ptr() as *const u8,
        self.0.as_mut_ptr().add(160),
        160,
      );
    }
  }

  pub fn n3(&'a self) -> flatbuffers::Array<'a, Pai, 32> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 320) }
  }

  pub fn set_n3(&mut self, x: &[Pai; 32]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe {
      core::ptr::copy(
        x.as_ptr() as *const u8,
        self.0.as_mut_ptr().add(320),
        160,
      );
    }
  }

  pub fn n4(&'a self) -> flatbuffers::Array<'a, Pai, 32> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 480) }
  }

  pub fn set_n4(&mut self, x: &[Pai; 32]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe {
      core::ptr::copy(
        x.as_ptr() as *const u8,
        self.0.as_mut_ptr().add(480),
        160,
      );
    }
  }

  pub fn n5(&'a self) -> flatbuffers::Array<'a, Pai, 8> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 640) }
  }

  pub fn set_n5(&mut self, x: &[Pai; 8]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe {
      core::ptr::copy(
        x.as_ptr() as *const u8,
        self.0.as_mut_ptr().add(640),
        40,
      );
    }
  }

  pub fn length(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[680..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_length(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[680..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn unpack(&self) -> TakuT {
    TakuT {
      n1: { let n1 = self.n1(); flatbuffers::array_init(|i| n1.get(i).unpack()) },
      n2: { let n2 = self.n2(); flatbuffers::array_init(|i| n2.get(i).unpack()) },
      n3: { let n3 = self.n3(); flatbuffers::array_init(|i| n3.get(i).unpack()) },
      n4: { let n4 = self.n4(); flatbuffers::array_init(|i| n4.get(i).unpack()) },
      n5: { let n5 = self.n5(); flatbuffers::array_init(|i| n5.get(i).unpack()) },
      length: self.length(),
    }
  }
}

#[derive(Debug, Clone, PartialEq, Default)]
pub struct TakuT {
  pub n1: [PaiT; 32],
  pub n2: [PaiT; 32],
  pub n3: [PaiT; 32],
  pub n4: [PaiT; 32],
  pub n5: [PaiT; 8],
  pub length: u32,
}
impl TakuT {
  pub fn pack(&self) -> Taku {
    Taku::new(
      &flatbuffers::array_init(|i| self.n1[i].pack()),
      &flatbuffers::array_init(|i| self.n2[i].pack()),
      &flatbuffers::array_init(|i| self.n3[i].pack()),
      &flatbuffers::array_init(|i| self.n4[i].pack()),
      &flatbuffers::array_init(|i| self.n5[i].pack()),
      self.length,
    )
  }
}

// struct MentsuPai, aligned to 1
#[repr(transparent)]
#[derive(Clone, Copy, PartialEq)]
pub struct MentsuPai(pub [u8; 3]);
impl Default for MentsuPai { 
  fn default() -> Self { 
    Self([0; 3])
  }
}
impl core::fmt::Debug for MentsuPai {
  fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {
    f.debug_struct("MentsuPai")
      .field("pai_num", &self.pai_num())
      .field("id", &self.id())
      .field("flag", &self.flag())
      .finish()
  }
}

impl flatbuffers::SimpleToVerifyInSlice for MentsuPai {}
impl<'a> flatbuffers::Follow<'a> for MentsuPai {
  type Inner = &'a MentsuPai;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    <&'a MentsuPai>::follow(buf, loc)
  }
}
impl<'a> flatbuffers::Follow<'a> for &'a MentsuPai {
  type Inner = &'a MentsuPai;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    flatbuffers::follow_cast_ref::<MentsuPai>(buf, loc)
  }
}
impl<'b> flatbuffers::Push for MentsuPai {
    type Output = MentsuPai;
    #[inline]
    unsafe fn push(&self, dst: &mut [u8], _written_len: usize) {
        let src = ::core::slice::from_raw_parts(self as *const MentsuPai as *const u8, Self::size());
        dst.copy_from_slice(src);
    }
}

impl<'a> flatbuffers::Verifiable for MentsuPai {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    v.in_buffer::<Self>(pos)
  }
}

impl<'a> MentsuPai {
  #[allow(clippy::too_many_arguments)]
  pub fn new(
    pai_num: u8,
    id: u8,
    flag: MentsuFlag,
  ) -> Self {
    let mut s = Self([0; 3]);
    s.set_pai_num(pai_num);
    s.set_id(id);
    s.set_flag(flag);
    s
  }

  pub fn pai_num(&self) -> u8 {
    let mut mem = core::mem::MaybeUninit::<<u8 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[0..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u8 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_pai_num(&mut self, x: u8) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[0..].as_mut_ptr(),
        core::mem::size_of::<<u8 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn id(&self) -> u8 {
    let mut mem = core::mem::MaybeUninit::<<u8 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[1..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u8 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_id(&mut self, x: u8) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[1..].as_mut_ptr(),
        core::mem::size_of::<<u8 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn flag(&self) -> MentsuFlag {
    let mut mem = core::mem::MaybeUninit::<<MentsuFlag as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[2..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<MentsuFlag as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_flag(&mut self, x: MentsuFlag) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[2..].as_mut_ptr(),
        core::mem::size_of::<<MentsuFlag as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn unpack(&self) -> MentsuPaiT {
    MentsuPaiT {
      pai_num: self.pai_num(),
      id: self.id(),
      flag: self.flag(),
    }
  }
}

#[derive(Debug, Clone, PartialEq, Default)]
pub struct MentsuPaiT {
  pub pai_num: u8,
  pub id: u8,
  pub flag: MentsuFlag,
}
impl MentsuPaiT {
  pub fn pack(&self) -> MentsuPai {
    MentsuPai::new(
      self.pai_num,
      self.id,
      self.flag,
    )
  }
}

// struct Mentsu, aligned to 4
#[repr(transparent)]
#[derive(Clone, Copy, PartialEq)]
pub struct Mentsu(pub [u8; 20]);
impl Default for Mentsu { 
  fn default() -> Self { 
    Self([0; 20])
  }
}
impl core::fmt::Debug for Mentsu {
  fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {
    f.debug_struct("Mentsu")
      .field("pai_list", &self.pai_list())
      .field("pai_len", &self.pai_len())
      .field("mentsu_type", &self.mentsu_type())
      .finish()
  }
}

impl flatbuffers::SimpleToVerifyInSlice for Mentsu {}
impl<'a> flatbuffers::Follow<'a> for Mentsu {
  type Inner = &'a Mentsu;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    <&'a Mentsu>::follow(buf, loc)
  }
}
impl<'a> flatbuffers::Follow<'a> for &'a Mentsu {
  type Inner = &'a Mentsu;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    flatbuffers::follow_cast_ref::<Mentsu>(buf, loc)
  }
}
impl<'b> flatbuffers::Push for Mentsu {
    type Output = Mentsu;
    #[inline]
    unsafe fn push(&self, dst: &mut [u8], _written_len: usize) {
        let src = ::core::slice::from_raw_parts(self as *const Mentsu as *const u8, Self::size());
        dst.copy_from_slice(src);
    }
}

impl<'a> flatbuffers::Verifiable for Mentsu {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    v.in_buffer::<Self>(pos)
  }
}

impl<'a> Mentsu {
  #[allow(clippy::too_many_arguments)]
  pub fn new(
    pai_list: &[MentsuPai; 4],
    pai_len: u32,
    mentsu_type: MentsuType,
  ) -> Self {
    let mut s = Self([0; 20]);
    s.set_pai_list(pai_list);
    s.set_pai_len(pai_len);
    s.set_mentsu_type(mentsu_type);
    s
  }

  pub fn pai_list(&'a self) -> flatbuffers::Array<'a, MentsuPai, 4> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 0) }
  }

  pub fn set_pai_list(&mut self, x: &[MentsuPai; 4]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe {
      core::ptr::copy(
        x.as_ptr() as *const u8,
        self.0.as_mut_ptr().add(0),
        12,
      );
    }
  }

  pub fn pai_len(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[12..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_pai_len(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[12..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn mentsu_type(&self) -> MentsuType {
    let mut mem = core::mem::MaybeUninit::<<MentsuType as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[16..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<MentsuType as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_mentsu_type(&mut self, x: MentsuType) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[16..].as_mut_ptr(),
        core::mem::size_of::<<MentsuType as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn unpack(&self) -> MentsuT {
    MentsuT {
      pai_list: { let pai_list = self.pai_list(); flatbuffers::array_init(|i| pai_list.get(i).unpack()) },
      pai_len: self.pai_len(),
      mentsu_type: self.mentsu_type(),
    }
  }
}

#[derive(Debug, Clone, PartialEq, Default)]
pub struct MentsuT {
  pub pai_list: [MentsuPaiT; 4],
  pub pai_len: u32,
  pub mentsu_type: MentsuType,
}
impl MentsuT {
  pub fn pack(&self) -> Mentsu {
    Mentsu::new(
      &flatbuffers::array_init(|i| self.pai_list[i].pack()),
      self.pai_len,
      self.mentsu_type,
    )
  }
}

// struct Player, aligned to 4
#[repr(transparent)]
#[derive(Clone, Copy, PartialEq)]
pub struct Player(pub [u8; 532]);
impl Default for Player { 
  fn default() -> Self { 
    Self([0; 532])
  }
}
impl core::fmt::Debug for Player {
  fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {
    f.debug_struct("Player")
      .field("name", &self.name())
      .field("mentsu", &self.mentsu())
      .field("mentsu_len", &self.mentsu_len())
      .field("tehai", &self.tehai())
      .field("tehai_len", &self.tehai_len())
      .field("kawahai", &self.kawahai())
      .field("kawahai_len", &self.kawahai_len())
      .field("tsumohai", &self.tsumohai())
      .field("is_tsumo", &self.is_tsumo())
      .field("is_riichi", &self.is_riichi())
      .field("is_ippatsu", &self.is_ippatsu())
      .field("score", &self.score())
      .field("cursol", &self.cursol())
      .finish()
  }
}

impl flatbuffers::SimpleToVerifyInSlice for Player {}
impl<'a> flatbuffers::Follow<'a> for Player {
  type Inner = &'a Player;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    <&'a Player>::follow(buf, loc)
  }
}
impl<'a> flatbuffers::Follow<'a> for &'a Player {
  type Inner = &'a Player;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    flatbuffers::follow_cast_ref::<Player>(buf, loc)
  }
}
impl<'b> flatbuffers::Push for Player {
    type Output = Player;
    #[inline]
    unsafe fn push(&self, dst: &mut [u8], _written_len: usize) {
        let src = ::core::slice::from_raw_parts(self as *const Player as *const u8, Self::size());
        dst.copy_from_slice(src);
    }
}

impl<'a> flatbuffers::Verifiable for Player {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    v.in_buffer::<Self>(pos)
  }
}

impl<'a> Player {
  #[allow(clippy::too_many_arguments)]
  pub fn new(
    name: &FixedString,
    mentsu: &[Mentsu; 4],
    mentsu_len: u32,
    tehai: &[Pai; 13],
    tehai_len: u32,
    kawahai: &[Pai; 20],
    kawahai_len: u32,
    tsumohai: &Pai,
    is_tsumo: bool,
    is_riichi: bool,
    is_ippatsu: bool,
    score: i32,
    cursol: u32,
  ) -> Self {
    let mut s = Self([0; 532]);
    s.set_name(name);
    s.set_mentsu(mentsu);
    s.set_mentsu_len(mentsu_len);
    s.set_tehai(tehai);
    s.set_tehai_len(tehai_len);
    s.set_kawahai(kawahai);
    s.set_kawahai_len(kawahai_len);
    s.set_tsumohai(tsumohai);
    s.set_is_tsumo(is_tsumo);
    s.set_is_riichi(is_riichi);
    s.set_is_ippatsu(is_ippatsu);
    s.set_score(score);
    s.set_cursol(cursol);
    s
  }

  pub fn name(&self) -> &FixedString {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid struct in this slot
    unsafe { &*(self.0[0..].as_ptr() as *const FixedString) }
  }

  #[allow(clippy::identity_op)]
  pub fn set_name(&mut self, x: &FixedString) {
    self.0[0..0 + 256].copy_from_slice(&x.0)
  }

  pub fn mentsu(&'a self) -> flatbuffers::Array<'a, Mentsu, 4> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 256) }
  }

  pub fn set_mentsu(&mut self, x: &[Mentsu; 4]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe {
      core::ptr::copy(
        x.as_ptr() as *const u8,
        self.0.as_mut_ptr().add(256),
        80,
      );
    }
  }

  pub fn mentsu_len(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[336..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_mentsu_len(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[336..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn tehai(&'a self) -> flatbuffers::Array<'a, Pai, 13> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 340) }
  }

  pub fn set_tehai(&mut self, x: &[Pai; 13]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe {
      core::ptr::copy(
        x.as_ptr() as *const u8,
        self.0.as_mut_ptr().add(340),
        65,
      );
    }
  }

  pub fn tehai_len(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[408..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_tehai_len(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[408..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn kawahai(&'a self) -> flatbuffers::Array<'a, Pai, 20> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 412) }
  }

  pub fn set_kawahai(&mut self, x: &[Pai; 20]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe {
      core::ptr::copy(
        x.as_ptr() as *const u8,
        self.0.as_mut_ptr().add(412),
        100,
      );
    }
  }

  pub fn kawahai_len(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[512..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_kawahai_len(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[512..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn tsumohai(&self) -> &Pai {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid struct in this slot
    unsafe { &*(self.0[516..].as_ptr() as *const Pai) }
  }

  #[allow(clippy::identity_op)]
  pub fn set_tsumohai(&mut self, x: &Pai) {
    self.0[516..516 + 5].copy_from_slice(&x.0)
  }

  pub fn is_tsumo(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[521..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_is_tsumo(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[521..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn is_riichi(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[522..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_is_riichi(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[522..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn is_ippatsu(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[523..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_is_ippatsu(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[523..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn score(&self) -> i32 {
    let mut mem = core::mem::MaybeUninit::<<i32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[524..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<i32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_score(&mut self, x: i32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[524..].as_mut_ptr(),
        core::mem::size_of::<<i32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn cursol(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[528..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_cursol(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[528..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn unpack(&self) -> PlayerT {
    PlayerT {
      name: self.name().unpack(),
      mentsu: { let mentsu = self.mentsu(); flatbuffers::array_init(|i| mentsu.get(i).unpack()) },
      mentsu_len: self.mentsu_len(),
      tehai: { let tehai = self.tehai(); flatbuffers::array_init(|i| tehai.get(i).unpack()) },
      tehai_len: self.tehai_len(),
      kawahai: { let kawahai = self.kawahai(); flatbuffers::array_init(|i| kawahai.get(i).unpack()) },
      kawahai_len: self.kawahai_len(),
      tsumohai: self.tsumohai().unpack(),
      is_tsumo: self.is_tsumo(),
      is_riichi: self.is_riichi(),
      is_ippatsu: self.is_ippatsu(),
      score: self.score(),
      cursol: self.cursol(),
    }
  }
}

#[derive(Debug, Clone, PartialEq, Default)]
pub struct PlayerT {
  pub name: FixedStringT,
  pub mentsu: [MentsuT; 4],
  pub mentsu_len: u32,
  pub tehai: [PaiT; 13],
  pub tehai_len: u32,
  pub kawahai: [PaiT; 20],
  pub kawahai_len: u32,
  pub tsumohai: PaiT,
  pub is_tsumo: bool,
  pub is_riichi: bool,
  pub is_ippatsu: bool,
  pub score: i32,
  pub cursol: u32,
}
impl PlayerT {
  pub fn pack(&self) -> Player {
    Player::new(
      &self.name.pack(),
      &flatbuffers::array_init(|i| self.mentsu[i].pack()),
      self.mentsu_len,
      &flatbuffers::array_init(|i| self.tehai[i].pack()),
      self.tehai_len,
      &flatbuffers::array_init(|i| self.kawahai[i].pack()),
      self.kawahai_len,
      &self.tsumohai.pack(),
      self.is_tsumo,
      self.is_riichi,
      self.is_ippatsu,
      self.score,
      self.cursol,
    )
  }
}

// struct Rule, aligned to 4
#[repr(transparent)]
#[derive(Clone, Copy, PartialEq)]
pub struct Rule(pub [u8; 60]);
impl Default for Rule { 
  fn default() -> Self { 
    Self([0; 60])
  }
}
impl core::fmt::Debug for Rule {
  fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {
    f.debug_struct("Rule")
      .field("enable_kuitan", &self.enable_kuitan())
      .field("enable_kansaki", &self.enable_kansaki())
      .field("enable_pao", &self.enable_pao())
      .field("double_ron_type", &self.double_ron_type())
      .field("initial_score", &self.initial_score())
      .field("enable_tobi", &self.enable_tobi())
      .field("enable_wareme", &self.enable_wareme())
      .field("aka_type", &self.aka_type())
      .field("shanyu_score", &self.shanyu_score())
      .field("nannyu_score", &self.nannyu_score())
      .field("enable_kuinaoshi", &self.enable_kuinaoshi())
      .field("uradora_type", &self.uradora_type())
      .field("enable_minus_riichi", &self.enable_minus_riichi())
      .field("enable_ryanhan_shibari", &self.enable_ryanhan_shibari())
      .field("furiten_riichi_type", &self.furiten_riichi_type())
      .field("enable_keiten", &self.enable_keiten())
      .field("oyanagare_type", &self.oyanagare_type())
      .field("kan_in_riichi", &self.kan_in_riichi())
      .field("enable_kiriage", &self.enable_kiriage())
      .field("enable_agariyame", &self.enable_agariyame())
      .finish()
  }
}

impl flatbuffers::SimpleToVerifyInSlice for Rule {}
impl<'a> flatbuffers::Follow<'a> for Rule {
  type Inner = &'a Rule;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    <&'a Rule>::follow(buf, loc)
  }
}
impl<'a> flatbuffers::Follow<'a> for &'a Rule {
  type Inner = &'a Rule;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    flatbuffers::follow_cast_ref::<Rule>(buf, loc)
  }
}
impl<'b> flatbuffers::Push for Rule {
    type Output = Rule;
    #[inline]
    unsafe fn push(&self, dst: &mut [u8], _written_len: usize) {
        let src = ::core::slice::from_raw_parts(self as *const Rule as *const u8, Self::size());
        dst.copy_from_slice(src);
    }
}

impl<'a> flatbuffers::Verifiable for Rule {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    v.in_buffer::<Self>(pos)
  }
}

impl<'a> Rule {
  #[allow(clippy::too_many_arguments)]
  pub fn new(
    enable_kuitan: bool,
    enable_kansaki: bool,
    enable_pao: bool,
    double_ron_type: u32,
    initial_score: u32,
    enable_tobi: bool,
    enable_wareme: bool,
    aka_type: u32,
    shanyu_score: i32,
    nannyu_score: i32,
    enable_kuinaoshi: bool,
    uradora_type: i32,
    enable_minus_riichi: bool,
    enable_ryanhan_shibari: bool,
    furiten_riichi_type: u32,
    enable_keiten: bool,
    oyanagare_type: u32,
    kan_in_riichi: u32,
    enable_kiriage: bool,
    enable_agariyame: bool,
  ) -> Self {
    let mut s = Self([0; 60]);
    s.set_enable_kuitan(enable_kuitan);
    s.set_enable_kansaki(enable_kansaki);
    s.set_enable_pao(enable_pao);
    s.set_double_ron_type(double_ron_type);
    s.set_initial_score(initial_score);
    s.set_enable_tobi(enable_tobi);
    s.set_enable_wareme(enable_wareme);
    s.set_aka_type(aka_type);
    s.set_shanyu_score(shanyu_score);
    s.set_nannyu_score(nannyu_score);
    s.set_enable_kuinaoshi(enable_kuinaoshi);
    s.set_uradora_type(uradora_type);
    s.set_enable_minus_riichi(enable_minus_riichi);
    s.set_enable_ryanhan_shibari(enable_ryanhan_shibari);
    s.set_furiten_riichi_type(furiten_riichi_type);
    s.set_enable_keiten(enable_keiten);
    s.set_oyanagare_type(oyanagare_type);
    s.set_kan_in_riichi(kan_in_riichi);
    s.set_enable_kiriage(enable_kiriage);
    s.set_enable_agariyame(enable_agariyame);
    s
  }

  pub fn enable_kuitan(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[0..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_enable_kuitan(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[0..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn enable_kansaki(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[1..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_enable_kansaki(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[1..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn enable_pao(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[2..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_enable_pao(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[2..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn double_ron_type(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[4..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_double_ron_type(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[4..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn initial_score(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[8..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_initial_score(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[8..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn enable_tobi(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[12..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_enable_tobi(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[12..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn enable_wareme(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[13..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_enable_wareme(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[13..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn aka_type(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[16..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_aka_type(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[16..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn shanyu_score(&self) -> i32 {
    let mut mem = core::mem::MaybeUninit::<<i32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[20..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<i32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_shanyu_score(&mut self, x: i32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[20..].as_mut_ptr(),
        core::mem::size_of::<<i32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn nannyu_score(&self) -> i32 {
    let mut mem = core::mem::MaybeUninit::<<i32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[24..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<i32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_nannyu_score(&mut self, x: i32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[24..].as_mut_ptr(),
        core::mem::size_of::<<i32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn enable_kuinaoshi(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[28..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_enable_kuinaoshi(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[28..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn uradora_type(&self) -> i32 {
    let mut mem = core::mem::MaybeUninit::<<i32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[32..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<i32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_uradora_type(&mut self, x: i32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[32..].as_mut_ptr(),
        core::mem::size_of::<<i32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn enable_minus_riichi(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[36..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_enable_minus_riichi(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[36..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn enable_ryanhan_shibari(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[37..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_enable_ryanhan_shibari(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[37..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn furiten_riichi_type(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[40..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_furiten_riichi_type(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[40..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn enable_keiten(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[44..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_enable_keiten(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[44..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn oyanagare_type(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[48..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_oyanagare_type(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[48..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn kan_in_riichi(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[52..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_kan_in_riichi(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[52..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn enable_kiriage(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[56..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_enable_kiriage(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[56..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn enable_agariyame(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[57..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_enable_agariyame(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[57..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn unpack(&self) -> RuleT {
    RuleT {
      enable_kuitan: self.enable_kuitan(),
      enable_kansaki: self.enable_kansaki(),
      enable_pao: self.enable_pao(),
      double_ron_type: self.double_ron_type(),
      initial_score: self.initial_score(),
      enable_tobi: self.enable_tobi(),
      enable_wareme: self.enable_wareme(),
      aka_type: self.aka_type(),
      shanyu_score: self.shanyu_score(),
      nannyu_score: self.nannyu_score(),
      enable_kuinaoshi: self.enable_kuinaoshi(),
      uradora_type: self.uradora_type(),
      enable_minus_riichi: self.enable_minus_riichi(),
      enable_ryanhan_shibari: self.enable_ryanhan_shibari(),
      furiten_riichi_type: self.furiten_riichi_type(),
      enable_keiten: self.enable_keiten(),
      oyanagare_type: self.oyanagare_type(),
      kan_in_riichi: self.kan_in_riichi(),
      enable_kiriage: self.enable_kiriage(),
      enable_agariyame: self.enable_agariyame(),
    }
  }
}

#[derive(Debug, Clone, PartialEq, Default)]
pub struct RuleT {
  pub enable_kuitan: bool,
  pub enable_kansaki: bool,
  pub enable_pao: bool,
  pub double_ron_type: u32,
  pub initial_score: u32,
  pub enable_tobi: bool,
  pub enable_wareme: bool,
  pub aka_type: u32,
  pub shanyu_score: i32,
  pub nannyu_score: i32,
  pub enable_kuinaoshi: bool,
  pub uradora_type: i32,
  pub enable_minus_riichi: bool,
  pub enable_ryanhan_shibari: bool,
  pub furiten_riichi_type: u32,
  pub enable_keiten: bool,
  pub oyanagare_type: u32,
  pub kan_in_riichi: u32,
  pub enable_kiriage: bool,
  pub enable_agariyame: bool,
}
impl RuleT {
  pub fn pack(&self) -> Rule {
    Rule::new(
      self.enable_kuitan,
      self.enable_kansaki,
      self.enable_pao,
      self.double_ron_type,
      self.initial_score,
      self.enable_tobi,
      self.enable_wareme,
      self.aka_type,
      self.shanyu_score,
      self.nannyu_score,
      self.enable_kuinaoshi,
      self.uradora_type,
      self.enable_minus_riichi,
      self.enable_ryanhan_shibari,
      self.furiten_riichi_type,
      self.enable_keiten,
      self.oyanagare_type,
      self.kan_in_riichi,
      self.enable_kiriage,
      self.enable_agariyame,
    )
  }
}

// struct GameState, aligned to 4
#[repr(transparent)]
#[derive(Clone, Copy, PartialEq)]
pub struct GameState(pub [u8; 3168]);
impl Default for GameState { 
  fn default() -> Self { 
    Self([0; 3168])
  }
}
impl core::fmt::Debug for GameState {
  fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {
    f.debug_struct("GameState")
      .field("title", &self.title())
      .field("players", &self.players())
      .field("player_len", &self.player_len())
      .field("bakaze", &self.bakaze())
      .field("oya", &self.oya())
      .field("tsumobou", &self.tsumobou())
      .field("riichibou", &self.riichibou())
      .field("teban", &self.teban())
      .field("taku", &self.taku())
      .field("taku_cursol", &self.taku_cursol())
      .field("dora_len", &self.dora_len())
      .field("uradora_len", &self.uradora_len())
      .field("is_non_duplicate", &self.is_non_duplicate())
      .field("rule", &self.rule())
      .finish()
  }
}

impl flatbuffers::SimpleToVerifyInSlice for GameState {}
impl<'a> flatbuffers::Follow<'a> for GameState {
  type Inner = &'a GameState;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    <&'a GameState>::follow(buf, loc)
  }
}
impl<'a> flatbuffers::Follow<'a> for &'a GameState {
  type Inner = &'a GameState;
  #[inline]
  unsafe fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    flatbuffers::follow_cast_ref::<GameState>(buf, loc)
  }
}
impl<'b> flatbuffers::Push for GameState {
    type Output = GameState;
    #[inline]
    unsafe fn push(&self, dst: &mut [u8], _written_len: usize) {
        let src = ::core::slice::from_raw_parts(self as *const GameState as *const u8, Self::size());
        dst.copy_from_slice(src);
    }
}

impl<'a> flatbuffers::Verifiable for GameState {
  #[inline]
  fn run_verifier(
    v: &mut flatbuffers::Verifier, pos: usize
  ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
    use self::flatbuffers::Verifiable;
    v.in_buffer::<Self>(pos)
  }
}

impl<'a> GameState {
  #[allow(clippy::too_many_arguments)]
  pub fn new(
    title: &FixedString,
    players: &[Player; 4],
    player_len: u32,
    bakaze: u32,
    oya: u32,
    tsumobou: u32,
    riichibou: u32,
    teban: u32,
    taku: &Taku,
    taku_cursol: u32,
    dora_len: u32,
    uradora_len: u32,
    is_non_duplicate: bool,
    rule: &Rule,
  ) -> Self {
    let mut s = Self([0; 3168]);
    s.set_title(title);
    s.set_players(players);
    s.set_player_len(player_len);
    s.set_bakaze(bakaze);
    s.set_oya(oya);
    s.set_tsumobou(tsumobou);
    s.set_riichibou(riichibou);
    s.set_teban(teban);
    s.set_taku(taku);
    s.set_taku_cursol(taku_cursol);
    s.set_dora_len(dora_len);
    s.set_uradora_len(uradora_len);
    s.set_is_non_duplicate(is_non_duplicate);
    s.set_rule(rule);
    s
  }

  pub fn title(&self) -> &FixedString {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid struct in this slot
    unsafe { &*(self.0[0..].as_ptr() as *const FixedString) }
  }

  #[allow(clippy::identity_op)]
  pub fn set_title(&mut self, x: &FixedString) {
    self.0[0..0 + 256].copy_from_slice(&x.0)
  }

  pub fn players(&'a self) -> flatbuffers::Array<'a, Player, 4> {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe { flatbuffers::Array::follow(&self.0, 256) }
  }

  pub fn set_players(&mut self, x: &[Player; 4]) {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid array in this slot
    unsafe {
      core::ptr::copy(
        x.as_ptr() as *const u8,
        self.0.as_mut_ptr().add(256),
        2128,
      );
    }
  }

  pub fn player_len(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[2384..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_player_len(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[2384..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn bakaze(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[2388..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_bakaze(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[2388..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn oya(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[2392..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_oya(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[2392..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn tsumobou(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[2396..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_tsumobou(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[2396..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn riichibou(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[2400..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_riichibou(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[2400..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn teban(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[2404..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_teban(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[2404..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn taku(&self) -> &Taku {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid struct in this slot
    unsafe { &*(self.0[2408..].as_ptr() as *const Taku) }
  }

  #[allow(clippy::identity_op)]
  pub fn set_taku(&mut self, x: &Taku) {
    self.0[2408..2408 + 684].copy_from_slice(&x.0)
  }

  pub fn taku_cursol(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[3092..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_taku_cursol(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[3092..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn dora_len(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[3096..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_dora_len(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[3096..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn uradora_len(&self) -> u32 {
    let mut mem = core::mem::MaybeUninit::<<u32 as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[3100..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_uradora_len(&mut self, x: u32) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[3100..].as_mut_ptr(),
        core::mem::size_of::<<u32 as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn is_non_duplicate(&self) -> bool {
    let mut mem = core::mem::MaybeUninit::<<bool as EndianScalar>::Scalar>::uninit();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    EndianScalar::from_little_endian(unsafe {
      core::ptr::copy_nonoverlapping(
        self.0[3104..].as_ptr(),
        mem.as_mut_ptr() as *mut u8,
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
      mem.assume_init()
    })
  }

  pub fn set_is_non_duplicate(&mut self, x: bool) {
    let x_le = x.to_little_endian();
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid value in this slot
    unsafe {
      core::ptr::copy_nonoverlapping(
        &x_le as *const _ as *const u8,
        self.0[3104..].as_mut_ptr(),
        core::mem::size_of::<<bool as EndianScalar>::Scalar>(),
      );
    }
  }

  pub fn rule(&self) -> &Rule {
    // Safety:
    // Created from a valid Table for this object
    // Which contains a valid struct in this slot
    unsafe { &*(self.0[3108..].as_ptr() as *const Rule) }
  }

  #[allow(clippy::identity_op)]
  pub fn set_rule(&mut self, x: &Rule) {
    self.0[3108..3108 + 60].copy_from_slice(&x.0)
  }

  pub fn unpack(&self) -> GameStateT {
    GameStateT {
      title: self.title().unpack(),
      players: { let players = self.players(); flatbuffers::array_init(|i| players.get(i).unpack()) },
      player_len: self.player_len(),
      bakaze: self.bakaze(),
      oya: self.oya(),
      tsumobou: self.tsumobou(),
      riichibou: self.riichibou(),
      teban: self.teban(),
      taku: self.taku().unpack(),
      taku_cursol: self.taku_cursol(),
      dora_len: self.dora_len(),
      uradora_len: self.uradora_len(),
      is_non_duplicate: self.is_non_duplicate(),
      rule: self.rule().unpack(),
    }
  }
}

#[derive(Debug, Clone, PartialEq, Default)]
pub struct GameStateT {
  pub title: FixedStringT,
  pub players: [PlayerT; 4],
  pub player_len: u32,
  pub bakaze: u32,
  pub oya: u32,
  pub tsumobou: u32,
  pub riichibou: u32,
  pub teban: u32,
  pub taku: TakuT,
  pub taku_cursol: u32,
  pub dora_len: u32,
  pub uradora_len: u32,
  pub is_non_duplicate: bool,
  pub rule: RuleT,
}
impl GameStateT {
  pub fn pack(&self) -> GameState {
    GameState::new(
      &self.title.pack(),
      &flatbuffers::array_init(|i| self.players[i].pack()),
      self.player_len,
      self.bakaze,
      self.oya,
      self.tsumobou,
      self.riichibou,
      self.teban,
      &self.taku.pack(),
      self.taku_cursol,
      self.dora_len,
      self.uradora_len,
      self.is_non_duplicate,
      &self.rule.pack(),
    )
  }
}

}  // pub mod OpenMahjong

